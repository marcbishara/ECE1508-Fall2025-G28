{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyN6aFxhXylfMCY37CFDaT7F"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"KweSVtAvnTNx","executionInfo":{"status":"ok","timestamp":1763933708679,"user_tz":300,"elapsed":22450,"user":{"displayName":"Tamara O'Connell","userId":"08436349544544283514"}}},"outputs":[],"source":["import torch\n","from transformers import AutoTokenizer, DistilBertForSequenceClassification, TrainingArguments, Trainer\n","from datasets import Dataset\n","\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TJIa36qtnzD7","executionInfo":{"status":"ok","timestamp":1763933739384,"user_tz":300,"elapsed":25957,"user":{"displayName":"Tamara O'Connell","userId":"08436349544544283514"}},"outputId":"c04e9ed8-c130-4ddf-fbc2-77e12b335c24"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["file_path = '/content/drive/My Drive/ECE1508(F3)-RL-Project/'"],"metadata":{"id":"lhk66sw1pRD9","executionInfo":{"status":"ok","timestamp":1763933891912,"user_tz":300,"elapsed":43,"user":{"displayName":"Tamara O'Connell","userId":"08436349544544283514"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["\n","# training checkpoint path\n","# checkpoint_path = f'files/SarcasmClassifierModel/checkpoint-2138'\n","\n","# load tokenizer\n","tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n","# tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n","\n","# load pre-trained DistilBERT sequence classification model\n","model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', id2label={0:'NEG',1:'POS'},label2id={'NEG':0,'POS':1})\n","# model = DistilBertForSequenceClassification.from_pretrained(checkpoint_path)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mzAiZ-4Xpm79","executionInfo":{"status":"ok","timestamp":1763933895233,"user_tz":300,"elapsed":2305,"user":{"displayName":"Tamara O'Connell","userId":"08436349544544283514"}},"outputId":"db5e5c79-1de6-4cb9-f04c-1d999400f74e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["# load training dataset\n","\n","## parent and child reddit comment, labeled as sarcastic or not\n","\n","data_total = pd.read_csv(file_path+'sarcasm_datasets/train-balanced-sarcasm.csv')\n","\n"],"metadata":{"id":"L6dEIEptqasw","executionInfo":{"status":"ok","timestamp":1763935851053,"user_tz":300,"elapsed":4796,"user":{"displayName":"Tamara O'Connell","userId":"08436349544544283514"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["print(data_total)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RrGhnvKhufPj","executionInfo":{"status":"ok","timestamp":1763935851062,"user_tz":300,"elapsed":5,"user":{"displayName":"Tamara O'Connell","userId":"08436349544544283514"}},"outputId":"e363429b-e3bb-42d4-ec77-784cdff008ff"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["         label                                            comment  \\\n","0            0                                         NC and NH.   \n","1            0  You do know west teams play against west teams...   \n","2            0  They were underdogs earlier today, but since G...   \n","3            0  This meme isn't funny none of the \"new york ni...   \n","4            0                    I could use one of those tools.   \n","...        ...                                                ...   \n","1010821      1  I'm sure that Iran and N. Korea have the techn...   \n","1010822      1                 whatever you do, don't vote green!   \n","1010823      1  Perhaps this is an atheist conspiracy to make ...   \n","1010824      1  The Slavs got their own country - it is called...   \n","1010825      1  values, as in capitalism .. there is good mone...   \n","\n","                 author           subreddit  score  ups  downs     date  \\\n","0             Trumpbart            politics      2   -1     -1  2016-10   \n","1             Shbshb906                 nba     -4   -1     -1  2016-11   \n","2              Creepeth                 nfl      3    3      0  2016-09   \n","3             icebrotha  BlackPeopleTwitter     -8   -1     -1  2016-10   \n","4             cush2push  MaddenUltimateTeam      6   -1     -1  2016-12   \n","...                 ...                 ...    ...  ...    ...      ...   \n","1010821       TwarkMain          reddit.com      2    2      0  2009-04   \n","1010822        BCHarvey             climate      1    1      0  2009-05   \n","1010823  rebelcommander             atheism      1    1      0  2009-01   \n","1010824           catsi           worldnews      1    1      0  2009-01   \n","1010825        frogking            politics      2    2      0  2009-01   \n","\n","                 created_utc  \\\n","0        2016-10-16 23:55:23   \n","1        2016-11-01 00:24:10   \n","2        2016-09-22 21:45:37   \n","3        2016-10-18 21:03:47   \n","4        2016-12-30 17:00:13   \n","...                      ...   \n","1010821  2009-04-25 00:47:52   \n","1010822  2009-05-14 22:27:40   \n","1010823  2009-01-11 00:22:57   \n","1010824  2009-01-23 21:12:49   \n","1010825  2009-01-24 06:20:14   \n","\n","                                            parent_comment  \n","0        Yeah, I get that argument. At this point, I'd ...  \n","1        The blazers and Mavericks (The wests 5 and 6 s...  \n","2                                  They're favored to win.  \n","3                               deadass don't kill my buzz  \n","4        Yep can confirm I saw the tool they use for th...  \n","...                                                    ...  \n","1010821  No one is calling this an engineered pathogen,...  \n","1010822  In a move typical of their recent do-nothing a...  \n","1010823  Screw the Disabled--I've got to get to Church ...  \n","1010824  I've always been unsettled by that. I hear a l...  \n","1010825  Why do the people who make our laws seem unabl...  \n","\n","[1010826 rows x 10 columns]\n"]}]},{"cell_type":"code","source":["# data cleaning\n","\n","# define the list of column names to drop\n","columns_to_drop = ['author', 'subreddit', 'score', 'ups', 'downs', 'date', 'created_utc']\n","\n","# drop columns\n","data_total = data_total.drop(columns=columns_to_drop)\n","\n","# drop rows wtih missing values\n","data_total = data_total.dropna()\n","\n","print(data_total)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IqpHgwVrnenM","executionInfo":{"status":"ok","timestamp":1763935856331,"user_tz":300,"elapsed":386,"user":{"displayName":"Tamara O'Connell","userId":"08436349544544283514"}},"outputId":"492d6fa6-3876-4013-b23d-969916c30d02"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["         label                                            comment  \\\n","0            0                                         NC and NH.   \n","1            0  You do know west teams play against west teams...   \n","2            0  They were underdogs earlier today, but since G...   \n","3            0  This meme isn't funny none of the \"new york ni...   \n","4            0                    I could use one of those tools.   \n","...        ...                                                ...   \n","1010821      1  I'm sure that Iran and N. Korea have the techn...   \n","1010822      1                 whatever you do, don't vote green!   \n","1010823      1  Perhaps this is an atheist conspiracy to make ...   \n","1010824      1  The Slavs got their own country - it is called...   \n","1010825      1  values, as in capitalism .. there is good mone...   \n","\n","                                            parent_comment  \n","0        Yeah, I get that argument. At this point, I'd ...  \n","1        The blazers and Mavericks (The wests 5 and 6 s...  \n","2                                  They're favored to win.  \n","3                               deadass don't kill my buzz  \n","4        Yep can confirm I saw the tool they use for th...  \n","...                                                    ...  \n","1010821  No one is calling this an engineered pathogen,...  \n","1010822  In a move typical of their recent do-nothing a...  \n","1010823  Screw the Disabled--I've got to get to Church ...  \n","1010824  I've always been unsettled by that. I hear a l...  \n","1010825  Why do the people who make our laws seem unabl...  \n","\n","[1010771 rows x 3 columns]\n"]}]},{"cell_type":"code","source":["# split the data to be 64% training, 16% validation and 20% test data\n","data_train_and_val, data_test = train_test_split(data_total, test_size=0.2, random_state=42)\n","data_train, data_val = train_test_split(data_train_and_val, test_size=0.2, random_state=42)\n","\n","print(data_train.shape, data_val.shape, data_test.shape)\n","\n","\n","# tokenize datasets\n","# string 'parent_comment' combined with 'comment', separated by [SEP] token\n","tr_tok = tokenizer(data_train['parent_comment'].tolist(), data_train['comment'].tolist(), return_tensors='pt', truncation=True, padding=True, max_length=128)\n","val_tok = tokenizer(data_val['parent_comment'].tolist(), data_val['comment'].tolist(), return_tensors='pt', truncation=True, padding=True, max_length=128)\n","test_tok = tokenizer(data_test['parent_comment'].tolist(), data_test['comment'].tolist(), return_tensors='pt', truncation=True, padding=True, max_length=128)\n","\n","# add tokenized outputs as new columns in dfs\n","data_train['input_ids'] = tr_tok['input_ids'].tolist()\n","data_train['attention_mask'] = tr_tok['attention_mask'].tolist()\n","\n","data_val['input_ids'] = val_tok['input_ids'].tolist()\n","data_val['attention_mask'] = val_tok['attention_mask'].tolist()\n","\n","data_test['input_ids'] = test_tok['input_ids'].tolist()\n","data_test['attention_mask'] = test_tok['attention_mask'].tolist()\n","\n","# convert to Hugging Face datasets\n","dataset_train = Dataset.from_pandas(data_train)\n","dataset_val = Dataset.from_pandas(data_val)\n","dataset_test = Dataset.from_pandas(data_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BDUPt47QqhGb","executionInfo":{"status":"ok","timestamp":1763936068648,"user_tz":300,"elapsed":183728,"user":{"displayName":"Tamara O'Connell","userId":"08436349544544283514"}},"outputId":"50b5b1ad-2ef3-4795-aa09-ffffd25736af"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["(646892, 3) (161724, 3) (202155, 3)\n"]}]},{"cell_type":"code","source":["# fine-tune training of model\n","\n","# set training arguments\n","training_args = TrainingArguments(\n","    output_dir=file_path+'files/SarcasmClassifierModel2',\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=16, ### TODO: Make batch size larger for faster training?\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=2,\n","    weight_decay=0.01,\n","    eval_strategy='epoch',\n","    save_strategy='epoch',\n","    load_best_model_at_end=True,\n","    push_to_hub=False, # do not intend to upload model to Hugging Face during training\n","    report_to='none',\n","    fp16=True,\n",")\n","\n","# define compute metrics\n","def compute_metrics(pred):\n","    logits, labels = pred\n","    predictions = np.argmax(logits, axis=-1)\n","\n","    # labels = pred.label_ids\n","    # preds = pred.predictions.argmax(-1)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='macro')\n","    acc = accuracy_score(labels, predictions)\n","    return {\n","        'Accuracy': acc,\n","        'F1': f1,\n","        'Precision': precision,\n","        'Recall': recall\n","    }\n","\n","\n","# initialize trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset_train,\n","    eval_dataset=dataset_val,\n","    # processing_class=tokenizer,\n","    # data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")\n"],"metadata":{"id":"tHgPpa26qJjG","executionInfo":{"status":"ok","timestamp":1763936093430,"user_tz":300,"elapsed":40,"user":{"displayName":"Tamara O'Connell","userId":"08436349544544283514"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["# train model\n","trainer.train()\n","# trainer.train(resume_from_checkpoint=checkpoint_path)\n","\n","# evaluate model\n","trainer.evaluate()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":415},"id":"-QeIXrNZp1AI","executionInfo":{"status":"ok","timestamp":1763938788319,"user_tz":300,"elapsed":1319645,"user":{"displayName":"Tamara O'Connell","userId":"08436349544544283514"}},"outputId":"91a0d57e-4326-48d7-c994-2e2a38d2e08b"},"execution_count":39,"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='44117' max='80862' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [44117/80862 22:45 < 18:57, 32.31 it/s, Epoch 1.09/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.478900</td>\n","      <td>0.477196</td>\n","      <td>0.772681</td>\n","      <td>0.772671</td>\n","      <td>0.772764</td>\n","      <td>0.772702</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='80862' max='80862' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [80862/80862 43:04, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.478900</td>\n","      <td>0.477196</td>\n","      <td>0.772681</td>\n","      <td>0.772671</td>\n","      <td>0.772764</td>\n","      <td>0.772702</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.405900</td>\n","      <td>0.481340</td>\n","      <td>0.777776</td>\n","      <td>0.777772</td>\n","      <td>0.777824</td>\n","      <td>0.777791</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='10108' max='10108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10108/10108 01:40]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 0.4771955609321594,\n"," 'eval_Accuracy': 0.7726806163587346,\n"," 'eval_F1': 0.772671233470531,\n"," 'eval_Precision': 0.7727644592561771,\n"," 'eval_Recall': 0.7727017421997169,\n"," 'eval_runtime': 100.4138,\n"," 'eval_samples_per_second': 1610.575,\n"," 'eval_steps_per_second': 100.663,\n"," 'epoch': 2.0}"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["# save model and tokenizer\n","model_save_path =file_path+'files/TrainedSarcasmClassifierModel2'\n","trainer.save_model(model_save_path)\n","tokenizer.save_pretrained(model_save_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GitqT7b1rQSc","executionInfo":{"status":"ok","timestamp":1763938834230,"user_tz":300,"elapsed":1315,"user":{"displayName":"Tamara O'Connell","userId":"08436349544544283514"}},"outputId":"315048fc-7eae-4e2e-f48d-5402380e8ed4"},"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('/content/drive/My Drive/ECE1508(F3)-RL-Project/files/TrainedSarcasmClassifierModel2/tokenizer_config.json',\n"," '/content/drive/My Drive/ECE1508(F3)-RL-Project/files/TrainedSarcasmClassifierModel2/special_tokens_map.json',\n"," '/content/drive/My Drive/ECE1508(F3)-RL-Project/files/TrainedSarcasmClassifierModel2/vocab.txt',\n"," '/content/drive/My Drive/ECE1508(F3)-RL-Project/files/TrainedSarcasmClassifierModel2/added_tokens.json',\n"," '/content/drive/My Drive/ECE1508(F3)-RL-Project/files/TrainedSarcasmClassifierModel2/tokenizer.json')"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["\n","# test code below\n","text1 = \"Time is the best teacher\"\n","text2 = \"Unfortunately it kills all its students!\"\n","inputs = tokenizer(text1, text2, return_tensors='pt')\n","\n","# Move inputs to the same device as the model\n","inputs = {k: v.to(model.device) for k, v in inputs.items()}\n","\n","outputs = model(**inputs)\n","predictions = outputs.logits.argmax(dim=-1).item()\n","\n","print(outputs)\n","print('predictions: ', predictions)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xfOkXbKQqw-9","executionInfo":{"status":"ok","timestamp":1763939333687,"user_tz":300,"elapsed":289,"user":{"displayName":"Tamara O'Connell","userId":"08436349544544283514"}},"outputId":"4af3f4ef-cb97-4fb0-a7f5-3721f5a6d990"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["SequenceClassifierOutput(loss=None, logits=tensor([[-0.6167,  0.6113]], device='cuda:0', grad_fn=<ToCopyBackward0>), hidden_states=None, attentions=None)\n","predictions:  1\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"fRKehLUh9LBU"},"execution_count":null,"outputs":[]}]}